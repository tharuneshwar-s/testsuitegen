# suite_gen/templates.py
# Jinja2 Templates for Test Suite Generation

# Template for testing raw Python functions (Unit Tests)
UNIT_TEST_TEMPLATE = """
import pytest
from {{ module_path }} import {{ function_name }}

# Auto-generated by TestSuiteGen
# Operation: {{ operation_id }}

class Test{{ operation_id | replace('_', '') }}:

    @pytest.mark.parametrize("intent, kwargs, expected_status", [
    {%- for case in test_cases %}
        pytest.param(
            "{{ case.intent }}",
            {{ case.payload }},
            {{ case.expected_status }},
            id="{{ case.intent }}"
        ),
    {%- endfor %}
    ])
    def test_{{ operation_id }}_contract(self, intent, kwargs, expected_status):
        \"\"\"
        Contract testing for {{ function_name }}.
        Intent: {intent}
        Expected: {expected_status} (400/422 = Exception)
        \"\"\"
        
        # Negative Tests (Expect Exceptions)
        if expected_status >= 400:
            # We expect TypeError for structural issues, ValueError for constraints, or AttributeError for None access
            with pytest.raises((ValueError, TypeError, AssertionError, AttributeError)):
                {{ function_name }}(**kwargs)
        
        # Happy Path (Expect Return Value)
        else:
            result = {{ function_name }}(**kwargs)
            assert result is not None
"""

# Template for testing HTTP APIs (Integration Tests) - Pytest
API_TEST_TEMPLATE = """
import pytest
import requests
from typing import Dict, Any, Optional
import uuid

BASE_URL = "{{ base_url }}"
ENDPOINT = "{{ path }}"
METHOD = "{{ method }}"

# Operation: {{ operation_id }}
# Error Codes Expected: {{ error_codes | join(', ') }}


@pytest.fixture(scope="module")
def api_client():
    '''Provides a configured API client for testing.'''
    session = requests.Session()
    session.headers.update({"Content-Type": "application/json"})
    yield session
    session.close()


@pytest.fixture(scope="class")
def test_data_setup(api_client):
    '''
    Setup fixture that creates test data before tests and cleans up after.
    This ensures each test run has a clean state.
    '''
    created_resources = []
    
    # Setup: Create any prerequisite test data here
    # Example: If testing user operations, create test users
    {% if 'user_id' in path_param_names or 'id' in path_param_names %}
    # Create test resource for path parameter testing
    setup_payload = {
        "username": f"test_user_{uuid.uuid4().hex[:8]}",
        "email": f"test_{uuid.uuid4().hex[:8]}@example.com",
        "password": "TestPassword123!",
        "full_name": "Test User",
        "age": 25
    }
    try:
        # Attempt to create a test resource
        response = api_client.post(f"{BASE_URL}/users", json=setup_payload)
        if response.status_code in (200, 201):
            resource_data = response.json()
            created_resources.append({
                "type": "user",
                "id": resource_data.get("id"),
                "endpoint": f"{BASE_URL}/users/{resource_data.get('id')}"
            })
    except Exception as e:
        print(f"Setup warning: Could not create test data: {e}")
    {% endif %}
    
    yield {"created_resources": created_resources}
    
    # Teardown: Clean up all created resources
    for resource in created_resources:
        try:
            api_client.delete(resource["endpoint"])
        except Exception as e:
            print(f"Cleanup warning: Could not delete {resource['type']} {resource['id']}: {e}")


class Test{{ operation_id | title }}:
    '''Test suite for {{ method }} {{ path }} endpoint.'''
    
    @pytest.fixture(autouse=True)
    def setup_method_fixture(self, test_data_setup):
        '''Automatically inject test data setup for each test method.'''
        self.test_data = test_data_setup
        yield
        # Per-test cleanup can go here if needed

    @pytest.mark.parametrize("intent, payload, path_params, expected_status", [
    {%- for case in test_cases %}
        pytest.param(
            "{{ case.intent }}",
            {{ case.payload }},
            {{ case.path_params if case.path_params else '{}' }},
            {{ case.expected_status }},
            id="{{ case.intent }}"
        ),
    {%- endfor %}
    ])
    def test_{{ operation_id }}_contract(self, api_client, intent, payload, path_params, expected_status):
        \"\"\"
        Validates {{ method }} {{ path }} against the OpenAPI contract.
        Intent: {{"{intent}"}}
        Expected Status: {{"{expected_status}"}}
        
        {% if error_info %}
        Error Response Information:
        {%- for error in error_info %}
        - Status {{ error.status }}: {{ error.description }}
          {%- if error.schema %}
          Response Schema: {{ error.schema_summary }}
          {%- endif %}
        {%- endfor %}
        {% endif %}
        \"\"\"
        url = f"{BASE_URL}{ENDPOINT}"
        
        {% raw %}# Replace path parameters with test data if available
        if path_params:
            for param_name, param_value in path_params.items():
                # Use created test resource ID if available and param_value is not set
                if param_value is None and hasattr(self, 'test_data') and self.test_data.get('created_resources'):
                    for resource in self.test_data['created_resources']:
                        param_value = resource.get('id', 1)
                        break
                # Handle INVALID_TYPE for path parameters
                if param_value == "__INVALID_TYPE__":
                    param_value = "invalid_string_value"
                url = url.replace(f"{{{param_name}}}", str(param_value))
        
        # Handle any remaining unreplaced path parameters (use test data)
        if "{" in url and hasattr(self, 'test_data') and self.test_data.get('created_resources'):
            for resource in self.test_data['created_resources']:
                # Replace any remaining path parameters with the resource ID
                import re
                url = re.sub(r'\\{\\w+\\}', str(resource.get('id', 1)), url)
                break
        
        # Extract query parameters from payload
        query_params = {}
        if payload and METHOD in ("GET", "DELETE"):
            # For GET/DELETE, move payload to query params
            query_params = payload.copy()
            payload = None
        
        # Generate unique data for creation tests to avoid conflicts
        if METHOD in ("POST", "PUT", "PATCH") and payload and intent == "HAPPY_PATH":
            if "username" in payload:
                payload["username"] = f"{payload['username']}_{uuid.uuid4().hex[:8]}"
            if "email" in payload:
                email_parts = payload["email"].split("@")
                payload["email"] = f"{email_parts[0]}_{uuid.uuid4().hex[:8]}@{email_parts[1]}"
        {% endraw %}
        
        response = api_client.request(
            method=METHOD,
            url=url,
            json=payload if payload else None,
            {% raw %}params=query_params if query_params else None,{% endraw %}
            headers={"Content-Type": "application/json"}
        )
        
        {% raw %}assert response.status_code == expected_status, \
            f"Failed Intent: {intent}. Expected {expected_status}, got {response.status_code}. Body: {response.text}"
        
        # Store created resource for cleanup if this is a creation test
        if response.status_code in (200, 201) and METHOD == "POST" and hasattr(self, 'test_data'):
            try:
                resource_data = response.json()
                if isinstance(resource_data, dict):
                    res_id = resource_data.get("id")
                    if res_id:
                        self.test_data['created_resources'].append({
                            "type": "test_resource",
                            "id": res_id,
                            "endpoint": f"{url}/{res_id}"
                        })
            except Exception:
                pass
        {% endraw %}
        
        # Validate error response structure if applicable
        if expected_status >= 400 and response.content:
            try:
                error_body = response.json()
                assert error_body is not None, "Error response should have a JSON body"
                # Additional validation can be added here based on error schema
            except ValueError:
                # Some error responses might not have JSON body
                pass

"""

# Template for testing HTTP APIs (Integration Tests) - Jest
# NOTE: This template intentionally avoids TypeScript-only syntax so it can run
# under a plain Jest setup without ts-jest/babel TypeScript presets.
OPENAPI_JEST_TEST_TEMPLATE = """
// Uses native fetch (Node.js 18+)

describe("{{ method }} {{ path }} ({{ operation_id }})", () => {
  const BASE_URL = "{{ base_url }}";
  const ENDPOINT = "{{ path }}";
  const METHOD = "{{ method }}";

  // Operation: {{ operation_id }}
  // Error Codes Expected: {{ error_codes | join(', ') }}

  const testCases = [
  {% for case in test_cases %}
    {
      intent: "{{ case.intent }}",
      payload: {{ case.payload }},
      pathParams: {{ case.path_params if case.path_params else '{}' }},
      expectedStatus: {{ case.expected_status }},
    },
  {% endfor %}
  ];

  it.each(testCases)("intent: %s", async (testCase) => {
    const { intent, payload, pathParams, expectedStatus } = testCase;

    let url = `${BASE_URL}${ENDPOINT}`;

    if (pathParams) {
      for (const [name, value] of Object.entries(pathParams)) {
        const paramValue =
          value === "__INVALID_TYPE__" ? "invalid_string_value" : value ?? 1;
        url = url.replace(`:${name}`, String(paramValue)).replace(
          `{${name}}`,
          String(paramValue),
        );
      }
    }

    const init: any = {
      method: METHOD,
      headers: { "Content-Type": "application/json" },
    };

    if (payload && (METHOD === "POST" || METHOD === "PUT" || METHOD === "PATCH")) {
      init.body = JSON.stringify(payload);
    }

    const response = await fetch(url, init);

    expect(response.status).toBe(
      expectedStatus,
    );

    if (expectedStatus >= 400) {
      try {
        const body = await response.json();
        expect(body).toBeDefined();
      } catch {
        // Some error responses might not have JSON body
      }
    }
  });
});

export {};
"""

# Template for testing TypeScript functions (Jest)
TYPESCRIPT_FUNCTION_TEST_TEMPLATE = """
import { {{ function_name }} } from "{{ module_path }}";

// Auto-generated by TestSuiteGen
// Operation: {{ operation_id }}

const testCases: any[] = [
{% for case in test_cases %}
  {
    intent: "{{ case.intent }}",
    args: {{ case.payload }},
    expectedStatus: {{ case.expected_status }},
  },
{% endfor %}
];

describe("{{ operation_id }}", () => {
  it.each(testCases)("intent: %s", async (testCase: any) => {
    const { intent, args, expectedStatus } = testCase;

    if (expectedStatus >= 400) {
      await expect(async () => {
        // @ts-ignore
        return await ({{ function_name }})(...Object.values(args));
      }).rejects.toThrow();
    } else {
      // @ts-ignore
      const result = await ({{ function_name }})(...Object.values(args));
      expect(result).toBeDefined();
    }
  });
});
"""
